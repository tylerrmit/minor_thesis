{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f09f1a5",
   "metadata": {},
   "source": [
    "# 05. Model Training Setup\n",
    "\n",
    "Given a dataset of labelled training images, create a label map configuration file and Tensorflow train/test tfrecords to be used in the training of a variety of potential object detection models from the TensorFlow 2 Model Garden\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e278c3",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Any configuration that is required to run this notebook can be customized in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bae11a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefix that will be included as a suffix in the label map file and tfrecord train and test files\n",
    "# Please ensure that you have put the required train and test images, with their label files from\n",
    "# lableImg, into the directory TensorFlow/workspace/imsages/train_XXX and test_XXX, where XXX is\n",
    "# the dataset_version you specify below\n",
    "\n",
    "dataset_version = 'V1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96860061",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3610368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import wget\n",
    "\n",
    "# Make sure local modules can be imported\n",
    "module_path_root = os.path.abspath(os.pardir)\n",
    "if module_path_root not in sys.path:\n",
    "    sys.path.append(module_path_root)\n",
    "    \n",
    "# Get root install path, a level above the minor_thesis folder from GitHub\n",
    "install_path_root = Path(module_path_root).parent.absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cfbb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derived paths\n",
    "api_dir             = os.path.join(install_path_root, 'TensorFlow', 'models')\n",
    "protoc_dir          = os.path.join(install_path_root, 'TensorFlow', 'protoc')\n",
    "annotations_dir     = os.path.join(install_path_root, 'TensorFlow', 'workspace', 'annotations')\n",
    "image_train_dir     = os.path.join(install_path_root, 'TensorFlow', 'workspace', 'images', 'train_{0:s}'.format(dataset_version))\n",
    "image_test_dir      = os.path.join(install_path_root, 'TensorFlow', 'workspace', 'images', 'test_{0:s}'.format(dataset_version))\n",
    "\n",
    "label_map_path      = os.path.join(annotations_dir, 'label_map_{0:s}.pbtxt'.format(dataset_version))\n",
    "train_record_path   = os.path.join(annotations_dir, 'train_{0:s}.record'.format(dataset_version))\n",
    "test_record_path    = os.path.join(annotations_dir, 'test_{0:s}.record'.format(dataset_version))\n",
    "\n",
    "tf_record_script    = os.path.join(module_path_root, 'contrib', 'generate_tfrecord.py')\n",
    "verification_script = os.path.join(api_dir, 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "\n",
    "# Create directories if they do not already exist\n",
    "Path(annotations_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(protoc_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(image_train_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(image_test_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6847eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the TensorFlow Model Garden API if it has not already been downloaded\n",
    "# This step may take a while if it has not already been run, otherwise it will\n",
    "# return quickly\n",
    "if not os.path.exists(os.path.join(api_dir, 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {api_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dfacbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Tensorflow Object Detection if it has not already been installed\n",
    "# This step may also take a few moments if it has not been run before\n",
    "# Ignore the message about \"The system cannot find the path specified\"\n",
    "# as long as it eventually says \"Successfully installed slim\"\n",
    "if not os.path.exists(os.path.join(protoc_dir, 'readme.txt')):\n",
    "    if os.name=='posix':  \n",
    "        !apt-get install protobuf-compiler\n",
    "        !cd TensorFlow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
    "    \n",
    "    if os.name=='nt':\n",
    "        url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "        wget.download(url)\n",
    "        !move protoc-3.15.6-win64.zip {protoc_dir}\n",
    "        !cd {protoc_dir} && tar -xf protoc-3.15.6-win64.zip\n",
    "        os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(protoc_dir, 'bin'))\n",
    "        !cd TensorFlow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "        slim_path = os.path.join(install_path_root, 'TensorFlow', 'models', 'research', 'slim')\n",
    "        !cd {slim_path} && pip install -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3685ba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a verification script to check that TensorFlow is installed and working\n",
    "# This script may return some errors due to issues with release management, but check for missing dependencies\n",
    "# And check that it says the GPU is found, if there is one\n",
    "!python {verification_script}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e31184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Label Map file\n",
    "labels = [\n",
    "    {'name':'BikeLaneMarker', 'id':1},\n",
    "    {'name':'GiveWayMarker',  'id':2},\n",
    "    {'name':'IslandMarker',   'id':3},\n",
    "    {'name':'ArrowMarker',    'id':4},\n",
    "    {'name':'RoadDefect',     'id':5},\n",
    "    {'name':'RoadWriting',    'id':6}\n",
    "]\n",
    "\n",
    "with open(label_map_path, 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155fbb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorFlow records from the images in the train and test directories\n",
    "# This step will take at least a few seconds, depending on the volume of images in the dataset\n",
    "!python {tf_record_script} -x {image_train_dir} -l {label_map_path} -o {train_record_path}\n",
    "!python {tf_record_script} -x {image_test_dir}  -l {label_map_path} -o {test_record_path}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuEnv",
   "language": "python",
   "name": "gpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
