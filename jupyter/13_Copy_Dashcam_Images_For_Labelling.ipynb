{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d26eb802",
   "metadata": {},
   "source": [
    "# 13. Copy Dashcam Images for Labelling\n",
    "\n",
    "In the previous notebook 12, we split dashcam footage into images and metadata, ready to be processed by a detection model.  We can jump straight ahead to notebook 15 to apply the previous detection model that was trained on GSV images to the dashcam images.  And we did.\n",
    "\n",
    "Naively running the old GSV model against the dashcam images, we come up with many \"hits\".  Most true-positive, but some false positives due to e.g.:\n",
    "\n",
    "* White markings on the road (give way stripes, traffic islands, turning arrows)\n",
    "* Reflections off the bonnet of the camera vehicle\n",
    "* White clouds or objects way off to the side of the road\n",
    "* etc.\n",
    "\n",
    "It also didn't perform as well as it could have, in that it only detected the bicycle lane markings when they were very close to the camera, rather than detecting them when they are clear but further into the distance.\n",
    "\n",
    "So we now want to use \"hits\" from that initial pass to enhance the training and validation dataset, to include actual dashcam images from the true positives and the false positives.\n",
    "\n",
    "To discourage the model from some of the false positives, we create new classes such as \"GiveWayMarker\" or \"ArrowMarker\" to explicitly label what they ARE.  This will hopefully give the object detection model a way to more confidently label them as something else!\n",
    "\n",
    "So in this notebook, we do three things:\n",
    "\n",
    "* Copy the \"hits\" from the first pass into the \"dataset\" directory\n",
    "* Stop and label them with labelImg\n",
    "* Split them into the \"train\" and \"test\" directories to create a larger dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e470f7",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Any configuration that is required to run this notebook can be customized in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a6fa26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the subdirectory containing dashcam footage for an area, split into frame images in a\n",
    "# \"split\" subdirectory, with a detection log in \"detections/detection_log.csv\"\n",
    "# This subdirectory is assumed to be in the 'data_sources' directory\n",
    "import_directory = 'dashcam_tour_mount_eliza'\n",
    "#import_directory = 'dashcam_tour_frankston'\n",
    "\n",
    "# Version suffix for the previous dataset.  We will copy existing images from here, and add to them.\n",
    "input_version = 'V1'\n",
    "\n",
    "# Version suffix for the new dataset being created, with additional images.\n",
    "output_version = 'V2'\n",
    "\n",
    "# Test split percentage\n",
    "# What percentage is held aside and moved into \"test_XXX\", while the rest are moved to \"train_XXX\"\n",
    "# (where \"XXX\" is the dataset_version string, above)\n",
    "# The actual number of images placed in \"test_XXX\" will be rounded DOWN\n",
    "test_split_percentage = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad0021b",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "843c1f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "\n",
    "# Make sure local modules can be imported\n",
    "module_path_root = os.path.abspath(os.pardir)\n",
    "if module_path_root not in sys.path:\n",
    "    sys.path.append(module_path_root)\n",
    "    \n",
    "# Get root install path, a level above the minor_thesis folder from GitHub\n",
    "install_path_root = Path(module_path_root).parent.absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e102b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derived path for input detection log with original image paths\n",
    "detection_log_path = os.path.join(module_path_root, 'data_sources', import_directory, 'detections', 'detection_log.csv')\n",
    "\n",
    "# Derived path for main dataset images directory, train images directory, and test images directory\n",
    "prev_image_train_dir   = os.path.join(install_path_root, 'TensorFlow', 'workspace', 'images', 'train_{0:s}'.format(input_version))\n",
    "prev_image_test_dir    = os.path.join(install_path_root, 'TensorFlow', 'workspace', 'images', 'test_{0:s}'.format(input_version))\n",
    "next_image_dataset_dir = os.path.join(install_path_root, 'TensorFlow', 'workspace', 'images', 'dataset_{0:s}'.format(output_dataset_version))\n",
    "next_image_train_dir   = os.path.join(install_path_root, 'TensorFlow', 'workspace', 'images', 'train_{0:s}'.format(output_version))\n",
    "next_image_test_dir    = os.path.join(install_path_root, 'TensorFlow', 'workspace', 'images', 'test_{0:s}'.format(output_version))\n",
    "\n",
    "# Create the output directories, if they do not already exist\n",
    "Path(next_image_dataset_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(next_image_train_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(next_image_test_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6818c9f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>bearing</th>\n",
       "      <th>heading</th>\n",
       "      <th>way_id_start</th>\n",
       "      <th>way_id</th>\n",
       "      <th>node_id</th>\n",
       "      <th>offset_id</th>\n",
       "      <th>score</th>\n",
       "      <th>bbox_0</th>\n",
       "      <th>bbox_1</th>\n",
       "      <th>bbox_2</th>\n",
       "      <th>bbox_3</th>\n",
       "      <th>orig_filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-38.208327</td>\n",
       "      <td>145.109764</td>\n",
       "      <td>346</td>\n",
       "      <td>346</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2148.0</td>\n",
       "      <td>0.732124</td>\n",
       "      <td>0.406723</td>\n",
       "      <td>0.374172</td>\n",
       "      <td>0.438563</td>\n",
       "      <td>0.415775</td>\n",
       "      <td>E:\\Release\\minor_thesis\\data_sources\\dashcam_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-38.204700</td>\n",
       "      <td>145.113683</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.614500</td>\n",
       "      <td>0.503657</td>\n",
       "      <td>0.293135</td>\n",
       "      <td>0.541611</td>\n",
       "      <td>0.354720</td>\n",
       "      <td>E:\\Release\\minor_thesis\\data_sources\\dashcam_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-38.204159</td>\n",
       "      <td>145.114524</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1776.0</td>\n",
       "      <td>0.652085</td>\n",
       "      <td>0.464327</td>\n",
       "      <td>0.315719</td>\n",
       "      <td>0.492939</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>E:\\Release\\minor_thesis\\data_sources\\dashcam_t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lat         lon  bearing  heading  way_id_start  way_id  node_id  \\\n",
       "0 -38.208327  145.109764      346      346             0       0        0   \n",
       "1 -38.204700  145.113683       65       65             0       0        0   \n",
       "2 -38.204159  145.114524       38       38             0       0        0   \n",
       "\n",
       "   offset_id     score    bbox_0    bbox_1    bbox_2    bbox_3  \\\n",
       "0     2148.0  0.732124  0.406723  0.374172  0.438563  0.415775   \n",
       "1     1332.0  0.614500  0.503657  0.293135  0.541611  0.354720   \n",
       "2     1776.0  0.652085  0.464327  0.315719  0.492939  0.359375   \n",
       "\n",
       "                                       orig_filename  \n",
       "0  E:\\Release\\minor_thesis\\data_sources\\dashcam_t...  \n",
       "1  E:\\Release\\minor_thesis\\data_sources\\dashcam_t...  \n",
       "2  E:\\Release\\minor_thesis\\data_sources\\dashcam_t...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read detection log\n",
    "df = pd.read_csv(detection_log_path)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c469ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be28fe6f26d64bd288efb781c0c16df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find each image file in the \"detection log\" CSV and copy them all to the \"dataset\" folder for the new version\n",
    "for index in trange(len(df)):\n",
    "    row = df.iloc[[index]]\n",
    "    \n",
    "    orig_filename = row['orig_filename'].item()\n",
    "        \n",
    "    output_filename = os.path.basename(orig_filename)\n",
    "    output_path     = os.path.join(next_image_dataset_dir, output_filename)\n",
    "    \n",
    "    shutil.copyfile(orig_filename, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2312de01",
   "metadata": {},
   "source": [
    "## Labelling\n",
    "\n",
    "Now, all the images for the dataset have been copied to the \"dataset_XXX\" directory in TensorFlow/workspace/images, where \"XXX\" is the suffix defined above in the configuration.\n",
    "\n",
    "The next step is to run \"labelImg\" from:\n",
    "\n",
    "https://github.com/tzutalin/labelImg\n",
    "\n",
    "Following the instructions on that webpage to install and run.\n",
    "\n",
    "You want to browse to the \"dataset_XXX\" directory, and label imagesswith the class names:\n",
    "\n",
    "* BikeLaneMarker\n",
    "* GiveWayMarker\n",
    "* IslandMarker\n",
    "* ArrowMarker\n",
    "* RoadDefect\n",
    "* RoadWriting\n",
    "\n",
    "Once all the labelling is done, you should have an XML file in that directory for every image.  Come back here and run the final phase of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6f2b58",
   "metadata": {},
   "source": [
    "## Training/Test split\n",
    "\n",
    "We now want to split the \"dataset_XXX\" directory into \"train_XXX\" and \"test_XXX\" directories according to a percentage split from the config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f5461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all label files in the dataset\n",
    "xml_file_list = [f for f in os.listdir(next_image_dataset_dir) if f.endswith('.xml')]\n",
    "\n",
    "# Determine how many images to sample for the \"test\" directory\n",
    "sample_size = math.floor(len(xml_file_list) * test_split_percentage / 100)\n",
    "\n",
    "# Randomly select from the list\n",
    "test_files = random.sample(xml_file_list, sample_size)\n",
    "\n",
    "# Move the sampled the XML files and their corresponding image file with a different extension\n",
    "for test_label_file in test_files:\n",
    "    test_label_base = os.path.splitext(test_label_file)[0]\n",
    "    \n",
    "    associated_files = [f for f in os.listdir(next_image_dataset_dir) if f.startswith(test_label_base + '.')]\n",
    "    for sample_file in associated_files:\n",
    "        print('Test  file: {0:s}'.format(sample_file))\n",
    "        input_path  = os.path.join(next_image_dataset_dir, sample_file)\n",
    "        output_path = os.path.join(next_image_test_dir,    sample_file)\n",
    "        \n",
    "        shutil.move(input_path, output_path)\n",
    "\n",
    "# Move any remaining files to the training directory\n",
    "remaining_file_list = os.listdir(next_image_dataset_dir)\n",
    "\n",
    "for training_file in remaining_file_list:\n",
    "    print('Train file: {0:s}'.format(training_file))\n",
    "    input_path  = os.path.join(next_image_dataset_dir, training_file)\n",
    "    output_path = os.path.join(next_image_train_dir,   training_file)\n",
    "    \n",
    "    shutil.move(input_path, output_path)\n",
    "    \n",
    "# Copy training images and test images from the previous version according to the previous split\n",
    "prev_train_file_list = os.listdir(prev_image_train_dir)\n",
    "\n",
    "for training_file in prev_train_file_list:\n",
    "    print('Prev Train file: {0:s}'.format(training_file))\n",
    "    \n",
    "    input_path  = os.path.join(prev_image_train_dir, training_file)\n",
    "    output_path = os.path.join(next_image_train_dir,   training_file)\n",
    "    \n",
    "    shutil.copyfile(input_path, output_path)\n",
    "\n",
    "prev_test_file_list = os.listdir(prev_image_test_dir)\n",
    "\n",
    "for test_file in prev_test_file_list:\n",
    "    print('Prev Test file: {0:s}'.format(test_file))\n",
    "    \n",
    "    input_path  = os.path.join(prev_image_test_dir, training_file)\n",
    "    output_path = os.path.join(next_image_test_dir,   training_file)\n",
    "    \n",
    "    shutil.copyfile(input_path, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
