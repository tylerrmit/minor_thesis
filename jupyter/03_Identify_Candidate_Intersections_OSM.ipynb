{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dominican-conspiracy",
   "metadata": {},
   "source": [
    "# 03. Identify Candidate Intersections OSM\n",
    "\n",
    "Build a CSV file with a list of candidate intersections to sample from Google Street View based purely on an OpenStreetMap XML extract.  We look for \"ways\" that have the tag \"cycleway\" and then find any nodes on those ways that are shared with another way.\n",
    "\n",
    "You can download OpenStreetMap XML data for Australia from:\n",
    "\n",
    "http://download.geofabrik.de\n",
    "\n",
    "And use the \"osmium\" tool to reduce it to a smaller bounding box.\n",
    "\n",
    "Or you can use the online service:\n",
    "\n",
    "https://extract.bbbike.org\n",
    "\n",
    "To select the required extract.  Please consider donating money to help them run that service, if you use it.\n",
    "\n",
    "The data for Victoria is 2.82GB uncompressed, so it is not included in the GitHub repository.  Please use one of the above service to obtain it.\n",
    "\n",
    "If downloading from geofabrik, the .osm.bz2 is a compressed version of the XML file you want, but you'll only be able to download Australia as a whole.  I recommend you download the .osm.pbf file -- a smaller file in a non-XML format -- and then use the \"osmium\" tool to cut it to a bounding box based on a pair of latitude/longitude coordinates.\n",
    "\n",
    "To install and use \"osmium\", see:\n",
    "\n",
    "https://osmcode.org/osmium-tool/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bfd82d",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Any configuration that is required to run this notebook can be customized in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43f587ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name of the output CSV files with a list of intersections to sample,\n",
    "# based on cycleways in the OSM extract\n",
    "# Will be saved to the 'data_sources' directory\n",
    "output_intersections_file = 'osm_intersections.csv'\n",
    "\n",
    "# Filename of OpenStreetMap XML extract that includes Victoria\n",
    "# Expected to be found in the 'data_sources' directory\n",
    "osm_file = 'planet_victoria.osm'\n",
    "#osm_file = 'Locality_Mount_Eliza_Sample.osm'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724fba26",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "immediate-school",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "\n",
    "from geographiclib.geodesic import Geodesic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4e81f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to help write log messages that keep track of how long everything took\n",
    "timestamp_starting = 0\n",
    "\n",
    "def log_starting(msg):\n",
    "    global timestamp_starting\n",
    "    timestamp_starting = datetime.now()\n",
    "    print(str(timestamp_starting) + ' START - ' + msg, flush=True)\n",
    "\n",
    "def log_finished(msg):\n",
    "    global timestamp_starting\n",
    "    timestamp_finished = datetime.now()\n",
    "    timestamp_duration = timestamp_finished - timestamp_starting\n",
    "    print(str(timestamp_finished) + ' END   - ' + msg\n",
    "        + '(' + str(timestamp_duration.total_seconds()) + ')',\n",
    "        flush=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-defensive",
   "metadata": {},
   "source": [
    "Load raw OpenStreetMap data for the area into memory.  This will be used to find all the intersections for each [local_street] x [town] mentioned in the PBN data.\n",
    "\n",
    "The extract was downloaded from http://extract.bbbike.org.  Region limited to one small down for initial testing, then a box that encompasses all of Victoria.\n",
    "\n",
    "The \"Victoria\" data took around 10 minutes to load into memory, and the resulting Python process used approximately 9GB of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mysterious-bicycle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-08 16:33:05.918598 START - Read raw OpenStreetMap data\n",
      "2021-10-08 16:37:17.708082 END   - Read raw OpenStreetMap data(251.789484)\n",
      "2021-10-08 16:37:17.708578 START - Find distinct way names per node\n",
      "2021-10-08 16:37:38.688859 END   - Find distinct way_names per node(20.980281)\n"
     ]
    }
   ],
   "source": [
    "osm_file_path = os.path.join(os.path.abspath(os.pardir), 'data_sources', osm_file)\n",
    "\n",
    "log_starting('Read raw OpenStreetMap data')\n",
    "\n",
    "# In-Memory caching via dictionary objects\n",
    "nodes_per_way      = defaultdict(list) # List of nodes in each way\n",
    "ways_per_node      = defaultdict(list) # List of way IDs associated with each node\n",
    "way_count_per_node = {}                # Count distinct way names per node\n",
    "ways_by_id         = {}                # List of ways by way id\n",
    "cycleways_by_id    = {}                # List of ways by way id where the way is a cycleway\n",
    "node_lat           = {}                # Latitude of an intersection node by oms_id\n",
    "node_lon           = {}                # Longitude of an intersection node by oms_id\n",
    "\n",
    "# Read the OpenStreetMap XML file\n",
    "context = ET.iterparse(osm_file_path, events=('start', 'end'))\n",
    "context = iter(context)\n",
    "\n",
    "way_id  = 0  # Keep track of which \"way\" object we are reading from XML, 0=none\n",
    "node_id = 0  # Keep track of which \"node\" (nd) object we are reading from XML, 0=none\n",
    "\n",
    "# Iterate through every XML element in the file as it starts or finishes\n",
    "# This approach allows us to \"stream\" the XML rather than try to load it all into\n",
    "# memory at once.  We only cache what is important to us.\n",
    "way_name    = None\n",
    "is_cycleway = False\n",
    "recorded    = False\n",
    "    \n",
    "for event, elem in context:\n",
    "    tag   = elem.tag\n",
    "    value = elem.text\n",
    "    \n",
    "    if value:\n",
    "        value = value.encode('utf-8').strip()\n",
    "        \n",
    "    # Process the start of an XML tag\n",
    "    if event == 'start':\n",
    "        # Process \"way\" objects\n",
    "        if tag == 'way':\n",
    "            way_id = elem.get('id', 0)\n",
    "                            \n",
    "            # Record that we have not found the name yet, nor evidence that it is a cycleway\n",
    "            way_name    = None\n",
    "            is_cycleway = False\n",
    "            recorded    = False\n",
    "            \n",
    "        # Process \"node\" (nd) objetcts inside (associated with) a \"way\"\n",
    "        elif tag == 'nd':\n",
    "            node_id = elem.get('ref', 0)\n",
    "            if way_id != 0:\n",
    "                # Record that this node was inside this way\n",
    "                nodes_per_way[way_id].append(node_id)\n",
    "                ways_per_node[node_id].append(way_id)\n",
    "                \n",
    "        # Process \"tag\" objects that give a street name for each \"way\"\n",
    "        elif tag == 'tag':\n",
    "            k = elem.get('k', '?').upper()\n",
    "            v = elem.get('v', '?').upper()\n",
    "            #print('Tag: [{0:s}] = [{1:s}]'.format(k, v))\n",
    "            \n",
    "            if way_id != 0 and k == 'NAME':\n",
    "                way_name = v\n",
    "                ways_by_id[way_id] = way_name.upper()\n",
    "            \n",
    "            elif way_id != 0 and k.startswith('CYCLEWAY'):\n",
    "                is_cycleway = True\n",
    "            \n",
    "            # If the way has a name and it is a cycleway that we have not yet recorded, do so now\n",
    "            if way_name is not None and is_cycleway and not recorded:\n",
    "                cycleways_by_id[way_id] = way_name.upper()\n",
    "                recorded = True\n",
    "\n",
    "        # Record the latitude/longitude for each \"node\" by its oms_id\n",
    "        if tag == 'node':\n",
    "            node_id = elem.get('id', 0)\n",
    "            lat     = elem.get('lat', 0)\n",
    "            lon     = elem.get('lon', 0)\n",
    "            \n",
    "            node_lat[node_id] = float(lat)\n",
    "            node_lon[node_id] = float(lon)\n",
    "            \n",
    "    # At the end of an XML tag, if it was a \"way\" then record that we are no longer\n",
    "    # in the middle of reading a \"way\"\n",
    "    if event == 'end' and tag == 'way':\n",
    "        way_id = 0\n",
    "\n",
    "    elem.clear()\n",
    "\n",
    "log_finished('Read raw OpenStreetMap data')\n",
    "\n",
    "\n",
    "# A way can be divided up into multiple segments when a characteristic changes, e.g. speed limit change\n",
    "# We do not want to recognise these boundaries of intersections, they're not\n",
    "# So get a count of distinct way names per node.  If there is more than one distinct name, THEN it is an intersection\n",
    "log_starting('Find distinct way names per node')\n",
    "\n",
    "for node_id in ways_per_node.keys():\n",
    "    way_names = []\n",
    "    \n",
    "    for way_id in ways_per_node[node_id]:\n",
    "        # Watch for unnamed ways that were deliberately excluded, e.g. coastline, creek\n",
    "        if way_id in ways_by_id:\n",
    "            way_name = ways_by_id[way_id]\n",
    "        \n",
    "            if way_name not in way_names:\n",
    "                way_names.append(way_name)\n",
    "    \n",
    "    way_count_per_node[node_id] = len(way_names)\n",
    "    \n",
    "log_finished('Find distinct way_names per node')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c048843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-08 16:37:38.702747 START - Write candidate intersections to CSV\n",
      "2021-10-08 16:37:42.718854 END   - Write candidate intersections to CSV(4.016107)\n"
     ]
    }
   ],
   "source": [
    "# Find intersections nodes in each cycleway, but try to work out the bearings at the same time\n",
    "# Write the output to a CSV\n",
    "\n",
    "log_starting('Write candidate intersections to CSV')\n",
    "\n",
    "output_intersections_path = os.path.join(os.path.abspath(os.pardir), 'data_sources', output_intersections_file)\n",
    "\n",
    "# Open an output CSV file for writing, emulate the basic structure of the one we produced from PBN cycleways\n",
    "f = open(output_intersections_path, 'w')\n",
    "f.write(',objectid,local_street,town_suburb,city_count,intersection_street,intersection_lat,intersection_lon,bearing,bearing_lat,bearing_lon\\n')\n",
    "\n",
    "for way_id in cycleways_by_id.keys():\n",
    "    node_list = nodes_per_way[way_id]\n",
    "    for i in range(0, len(node_list)):\n",
    "        this_node = node_list[i]\n",
    "        \n",
    "        if way_count_per_node[this_node] > 1:\n",
    "            # This is an intersection, we want to output it, but we need a bearing first\n",
    "            # The bearing is assumed to be the average of the bearing from the previous node to this node,\n",
    "            # and the bearing from this node to the next node\n",
    "        \n",
    "            if i > 0:\n",
    "                prev_node = node_list[i-1]\n",
    "                prev_bearing = Geodesic.WGS84.Inverse(node_lat[prev_node], node_lon[prev_node], node_lat[this_node], node_lon[this_node])['azi1']\n",
    "                if prev_bearing < 0:\n",
    "                    prev_bearing += 360\n",
    "            else:\n",
    "                prev_bearing = None\n",
    "            \n",
    "            if i < len(node_list) - 1:\n",
    "                next_node = node_list[i+1]\n",
    "                next_bearing = Geodesic.WGS84.Inverse(node_lat[this_node], node_lon[this_node], node_lat[next_node], node_lon[next_node])['azi1']\n",
    "                if next_bearing < 0:\n",
    "                    next_bearing += 360\n",
    "            else:\n",
    "                next_bearing = None\n",
    "        \n",
    "            if prev_bearing is not None and next_bearing is not None:\n",
    "                bearing = float((prev_bearing + next_bearing) / 2)\n",
    "            elif prev_bearing is not None:\n",
    "                bearing = float(prev_bearing)\n",
    "            elif next_bearing is not None:\n",
    "                bearing = float(next_bearing)\n",
    "            else:\n",
    "                bearing = 0\n",
    "                \n",
    "            # Output a record\n",
    "            f.write('0,{0:s},{1:s},-,-,-,1,{2:s},{3:.6f},{4:.6f},{5:.1f},{3:.6f},{4:.6f}\\n'.format(\n",
    "                way_id,\n",
    "                ways_by_id[way_id],\n",
    "                this_node,\n",
    "                node_lat[this_node],\n",
    "                node_lon[this_node],\n",
    "                bearing\n",
    "            ))\n",
    "            \n",
    "f.close()\n",
    "\n",
    "log_finished('Write candidate intersections to CSV')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
