{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dominican-conspiracy",
   "metadata": {},
   "source": [
    "# 03. Identify Candidate Intersections OSM\n",
    "\n",
    "Build a CSV file with a list of candidate intersections to sample from Google Street View based purely on an OpenStreetMap XML extract.  We look for \"ways\" that have the tag \"cycleway\" and then find any nodes on those ways that are shared with another way.\n",
    "\n",
    "You can download OpenStreetMap XML data for Australia from:\n",
    "\n",
    "http://download.geofabrik.de\n",
    "\n",
    "And use the \"osmium\" tool to reduce it to a smaller bounding box.\n",
    "\n",
    "Or you can use the online service:\n",
    "\n",
    "https://extract.bbbike.org\n",
    "\n",
    "To select the required extract.  Please consider donating money to help them run that service, if you use it.\n",
    "\n",
    "The data for Victoria is 2.82GB uncompressed, so it is not included in the GitHub repository.  Please use one of the above service to obtain it.\n",
    "\n",
    "If downloading from geofabrik, the .osm.bz2 is a compressed version of the XML file you want, but you'll only be able to download Australia as a whole.  I recommend you download the .osm.pbf file -- a smaller file in a non-XML format -- and then use the \"osmium\" tool to cut it to a bounding box based on a pair of latitude/longitude coordinates.\n",
    "\n",
    "To install and use \"osmium\", see:\n",
    "\n",
    "https://osmcode.org/osmium-tool/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bfd82d",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Any configuration that is required to run this notebook can be customized in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43f587ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name of the output CSV files with a list of intersections to sample,\n",
    "# based on cycleways in the OSM extract\n",
    "# Will be saved to the 'data_sources' directory\n",
    "output_intersections_file = 'osm_intersections.csv'\n",
    "\n",
    "# Filename of OpenStreetMap XML extract that includes Victoria\n",
    "# Expected to be found in the 'data_sources' directory\n",
    "osm_victoria_file = 'planet_victoria.osm'\n",
    "\n",
    "# Google Street View API key filename\n",
    "# To download Google Street View images via the API, you must have an API Key as per:\n",
    "#  https://developers.google.com/maps/documentation/streetview/get-api-key\n",
    "# linked to your Google account and billing information.  Otherwise they don't know who to charge,\n",
    "# so you won't be able to download the images.\n",
    "# Store your API key in a file with the name listed below, in the parent of the current working directory\n",
    "# from which you launched Jupyter Notebook\n",
    "# Do not share your API key with anyone else!\n",
    "gsv_api_key_filename = 'apikey.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724fba26",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "immediate-school",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4e81f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to help write log messages that keep track of how long everything took\n",
    "timestamp_starting = 0\n",
    "\n",
    "def log_starting(msg):\n",
    "    global timestamp_starting\n",
    "    timestamp_starting = datetime.now()\n",
    "    print(str(timestamp_starting) + ' START - ' + msg, flush=True)\n",
    "\n",
    "def log_finished(msg):\n",
    "    global timestamp_starting\n",
    "    timestamp_finished = datetime.now()\n",
    "    timestamp_duration = timestamp_finished - timestamp_starting\n",
    "    print(str(timestamp_finished) + ' END   - ' + msg\n",
    "        + '(' + str(timestamp_duration.total_seconds()) + ')',\n",
    "        flush=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-defensive",
   "metadata": {},
   "source": [
    "Load raw OpenStreetMap data for the area into memory.  This will be used to find all the intersections for each [local_street] x [town] mentioned in the PBN data.\n",
    "\n",
    "The extract was downloaded from http://extract.bbbike.org.  Region limited to one small down for initial testing, then a box that encompasses all of Victoria.\n",
    "\n",
    "The \"Victoria\" data took around 10 minutes to load into memory, and the resulting Python process used approximately 9GB of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-bicycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_file_path = os.path.join(os.path.abspath(os.pardir), 'data_sources', osm_victoria_file)\n",
    "\n",
    "log_starting('Read raw OpenStreetMap data')\n",
    "\n",
    "# In-Memory caching via dictionary objects\n",
    "nodes_per_way = defaultdict(list) # List of nodes in each way\n",
    "ways_per_node = defaultdict(list) # List of ways associated with each node\n",
    "ways_by_name  = defaultdict(list) # List of ways associated with each street name\n",
    "ways_by_id    = {}                # List of ways by osm_id\n",
    "node_lat      = {}                # Latitude of an intersection node by oms_id\n",
    "node_lon      = {}                # Longitude of an intersection node by oms_id\n",
    "\n",
    "# Read the OpenStreetMap XML file\n",
    "context = ET.iterparse(osm_file_path, events=('start', 'end'))\n",
    "context = iter(context)\n",
    "\n",
    "way_id  = 0  # Keep track of which \"way\" object we are reading from XML, 0=none\n",
    "node_id = 0  # Keep track of which \"node\" (nd) object we are reading from XML, 0=none\n",
    "\n",
    "# Iterate through every XML element in the file as it starts or finishes\n",
    "# This approach allows us to \"stream\" the XML rather than try to load it all into\n",
    "# memory at once.  We only cache what is important to us.\n",
    "for event, elem in context:\n",
    "    tag   = elem.tag\n",
    "    value = elem.text\n",
    "    \n",
    "    if value:\n",
    "        value = value.encode('utf-8').strip()\n",
    "    \n",
    "    # Process the start of an XML tag\n",
    "    if event == 'start':\n",
    "        # Process \"way\" objects\n",
    "        if tag == 'way':\n",
    "            way_id = elem.get('id', 0)\n",
    "        # Process \"node\" (nd) objetcts inside (associated with) a \"way\"\n",
    "        elif tag == 'nd':\n",
    "            node_id = elem.get('ref', 0)\n",
    "            if way_id != 0:\n",
    "                # Record that this node was inside this way\n",
    "                nodes_per_way[way_id].append(node_id)\n",
    "                ways_per_node[node_id].append(way_id)\n",
    "        # Process \"tag\" objects that give a street name for each \"way\"\n",
    "        elif tag == 'tag':\n",
    "            if way_id != 0 and elem.get('k', '?') == 'name':\n",
    "                way_name = elem.get('v', '?')\n",
    "                ways_by_name[way_name.upper()].append(way_id)\n",
    "                ways_by_id[way_id] = way_name.upper()\n",
    "                \n",
    "    # At the end of an XML tag, if it was a \"way\" then record that we are no longer\n",
    "    # in the middle of reading a \"way\"\n",
    "    if event == 'end' and tag == 'way':\n",
    "        way_id = 0\n",
    "\n",
    "    elem.clear()\n",
    "\n",
    "log_finished('Read raw OpenStreetMap data')\n",
    "\n",
    "\n",
    "# Second pass to load the latitude and longitude of nodes IF AND ONLY IF\n",
    "# they are involved in an intersection\n",
    "\n",
    "log_starting('Find Lat/Lon for intersections')\n",
    "\n",
    "context = ET.iterparse(osm_file_path, events=('start', 'end'))\n",
    "context = iter(context)\n",
    "\n",
    "way_id  = 0\n",
    "node_id = 0\n",
    "\n",
    "for event, elem in context:\n",
    "    tag   = elem.tag\n",
    "    value = elem.text\n",
    "    \n",
    "    if value:\n",
    "        value = value.encode('utf-8').strip()\n",
    "    \n",
    "    # Process the start of an XML tag\n",
    "    if event == 'start':\n",
    "        # Find the latitude/longitude for each \"node\" by its oms_id\n",
    "        if tag == 'node':\n",
    "            node_id = elem.get('id', 0)\n",
    "            lat     = elem.get('lat', 0)\n",
    "            lon     = elem.get('lon', 0)\n",
    "            \n",
    "            # If and only if this \"node\" had more than one \"way\" associated with it,\n",
    "            # it is part of an \"intersection\" and therefore we record its latitude\n",
    "            # and longitude in memory, by its oms_id\n",
    "            if len(ways_per_node[node_id]) > 1:\n",
    "                node_lat[node_id] = lat\n",
    "                node_lon[node_id] = lon\n",
    "\n",
    "    elem.clear()\n",
    "\n",
    "log_finished('Find Lat/Lon for intersections')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-banking",
   "metadata": {},
   "source": [
    "Define a function to directly call the Nominatim geocode service to turn lat/lon into geocoded information, because we need the \"bounding box\" part of the data, which is not returned by the Nominatim API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-hampton",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_nominatim_search = {}\n",
    "\n",
    "def nominatim_search(street, city):\n",
    "    # Check local cache first, used cached results if available\n",
    "    key = street + ' - ' + city\n",
    "    \n",
    "    if key in cached_nominatim_search:\n",
    "        return cached_nominatim_search[key]\n",
    "    \n",
    "    # api-endpoint\n",
    "    URL = 'http://' + nominatim_domain + '/search'\n",
    "    \n",
    "    params = {\n",
    "        'street': street,\n",
    "        'city': city\n",
    "    }\n",
    "        \n",
    "    # sending get request and saving the response as response object\n",
    "    r = requests.get(url = URL, params = params)\n",
    "    \n",
    "    # Cache results\n",
    "    cached_nominatim_search[key] = r.json()\n",
    "    \n",
    "    # extracting data in json format\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-conservative",
   "metadata": {},
   "source": [
    "Define a function to determine whether two bounding boxes overlap.  Include a \"margin\" to account for bounding boxes that almost overlap but are just off by a small margin, the size of an intersection or so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_overlapping(box1, box2, margin=0.05):\n",
    "    # Add margin to box1\n",
    "    box1_margin = []\n",
    "    box1_margin.append(box1[0] - margin)\n",
    "    box1_margin.append(box1[1] + margin)\n",
    "    box1_margin.append(box1[2] - margin)\n",
    "    box1_margin.append(box1[3] + margin)\n",
    "\n",
    "    #print('Margin: ' + str(box1_margin))\n",
    "    \n",
    "    # Check if latitude or longitude overlaps\n",
    "    lat_overlap = False\n",
    "    lon_overlap = False\n",
    "    \n",
    "    if box1_margin[0] <= box2[0] <= box1_margin[1]:\n",
    "        lat_overlap = True\n",
    "    if box1_margin[0] <= box2[1] <= box1_margin[1]:\n",
    "        lat_overlap = True\n",
    "    if box1_margin[2] <= box2[2] <= box1_margin[3]:\n",
    "        lon_overlap = True\n",
    "    if box1_margin[2] <= box2[3] <= box1_margin[3]:\n",
    "        lon_overlap = True\n",
    "        \n",
    "    return (lat_overlap and lon_overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-poison",
   "metadata": {},
   "source": [
    "Given a [local_street] x [town], find all other roads that intersect with it.\n",
    "\n",
    "Some roads like \"Main Street\" might be very common.  To avoid false-positives, we\n",
    "check the bounding boxes for both the original street and the candidate street that\n",
    "appears to intersect based on the [local_street] name alone.  If the bounding boxes\n",
    "overlap, or are close, then we are comfortable that it's not a duplicate street name\n",
    "from another area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-chaos",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_bounding_box(objectid):\n",
    "    row = pbn[pbn['objectid']==objectid]\n",
    "    \n",
    "    try:\n",
    "        gs = row['geometry']\n",
    "        return [gs.bounds['miny'][0], gs.bounds['maxy'][0], gs.bounds['minx'][0], gs.bounds['maxx'][0]]\n",
    "    except Exception:\n",
    "        return None\n",
    "    \n",
    "def inside_bounding_box(node_id, bounding_box, margin=0.05):\n",
    "    # Add margin to box1\n",
    "    box_margin = []\n",
    "    box_margin.append(bounding_box[0] - margin)\n",
    "    box_margin.append(bounding_box[1] + margin)\n",
    "    box_margin.append(bounding_box[2] - margin)\n",
    "    box_margin.append(bounding_box[3] + margin)\n",
    "    \n",
    "    if node_id not in node_lat:\n",
    "        return False\n",
    "    if node_id not in node_lon:\n",
    "        return False\n",
    "    if not (box_margin[0] <= float(node_lat[node_id]) <= box_margin[1]):\n",
    "        return False\n",
    "    if not (box_margin[2] <= float(node_lon[node_id]) <= box_margin[3]):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-reminder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_intersections(street, town, suburb, city, objectid=0, debug=0):\n",
    "    # Find bounding_box of original street\n",
    "    \n",
    "    # First try using information loaded from directly form PBN coordinates\n",
    "    original_bounding_box = lookup_bounding_box(objectid)\n",
    "    \n",
    "    if original_bounding_box is None:\n",
    "        # Use most specific first town->suburb->city\n",
    "        # E.g. Aberdeen Road Fyansford might actually be found in Geelong\n",
    "        original_street = nominatim_search(str(street).upper(), str(town).upper())\n",
    "    \n",
    "        if (len(original_street) < 1):\n",
    "            original_street = nominatim_search(str(street).upper(), str(suburb).upper())\n",
    "        \n",
    "            if (len(original_street) < 1):\n",
    "                original_street = nominatim_search(str(street).upper(), str(city).upper())\n",
    "            \n",
    "                if (len(original_street) < 1):\n",
    "                    return []\n",
    "    \n",
    "        original_bounding_box_str = original_street[0]['boundingbox']\n",
    "        original_bounding_box = [float(i) for i in original_bounding_box_str]\n",
    "    \n",
    "    if (debug > 2):\n",
    "        print('Original:  ' + street.upper() + \" = \" + str(original_bounding_box))\n",
    "    \n",
    "    # Find way_id list for the name\n",
    "    way_ids = ways_by_name[street.upper()]\n",
    "    \n",
    "    intersection_dict = {}\n",
    "    \n",
    "    # Find every matching street name (possibly in another suburb!)   \n",
    "    loop_counter = 0\n",
    "    \n",
    "    for way_id in way_ids:\n",
    "        # Find every node associated with that street name (including other suburbs)            \n",
    "        for node_id in nodes_per_way[way_id]:\n",
    "            # Check that this street is in the same area (probably the same suburb)\n",
    "            if inside_bounding_box(node_id, original_bounding_box):\n",
    "                # Find every other street the node is associated with                \n",
    "                for way_id2 in ways_per_node[node_id]:\n",
    "                    # Ignore any ways that were clipped from the map\n",
    "                    if way_id2 in ways_by_id:\n",
    "                        # Find the street name for the other potential intersecting street\n",
    "                        intersection_name = ways_by_id[way_id2]\n",
    "                        if intersection_name.upper() != street.upper():                        \n",
    "                            # Check Nominatim service to see if boundary boxes roughly overlap\n",
    "                        \n",
    "                            pot_streets = nominatim_search(intersection_name.upper(), city.upper())\n",
    "                            for pot_street in pot_streets:\n",
    "                                pot_street_bounding_box_str = pot_street['boundingbox']\n",
    "                                pot_street_bounding_box = [float(i) for i in pot_street_bounding_box_str]\n",
    "                            \n",
    "                                if (debug > 2):\n",
    "                                    print('Potential: ' + intersection_name + ' = ' + str(pot_street_bounding_box))\n",
    "                            \n",
    "                                if is_overlapping(original_bounding_box, pot_street_bounding_box):\n",
    "                                    if (debug > 2):\n",
    "                                        print('Matched: ' + intersection_name + ' = ' + str(pot_street_bounding_box) + ' vs ' + str(original_bounding_box))\n",
    "                                    intersection_dict[intersection_name] = [float(node_lat[node_id]), float(node_lon[node_id])]\n",
    "                                    if (debug > 2):\n",
    "                                        print('Trace: ' + str(node_id) + ' ' + intersection_name + ' => ' + str(intersection_dict[intersection_name]))\n",
    "                                loop_counter = loop_counter + 1\n",
    "    \n",
    "    if (debug > 0):\n",
    "        print(str(objectid) + ' ' + street + ' Matching Ways: ' + str(len(way_ids)) + ' loops: ' + str(loop_counter))\n",
    "    \n",
    "    # Transform dictionary into list of key/value pairs\n",
    "    intersection_list = []\n",
    "    \n",
    "    for intersection_name, intersection_details in intersection_dict.items():\n",
    "        intersection_entry = [intersection_name, intersection_details[0], intersection_details[1]]\n",
    "        intersection_list.append(intersection_entry)\n",
    "        \n",
    "    return intersection_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25abaed",
   "metadata": {},
   "source": [
    "Load original PBN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acf7abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_starting('Load original PBN dataset')\n",
    "\n",
    "pbn_path = os.path.join(os.path.abspath(os.pardir), 'data_sources', pbn_filename)\n",
    "\n",
    "pbn = gpd.read_file(pbn_path)\n",
    "\n",
    "log_finished('Load original PBN dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-wilson",
   "metadata": {},
   "source": [
    "Demonstration:  Find intersections for one street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-inspection",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_intersections('ABBEY WALK', 'VERMONT', 'VERMONT', 'VERMONT', 0, debug=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-confirmation",
   "metadata": {},
   "source": [
    "Get Google Maps API connection\n",
    "\n",
    "$6.70 AUD per 1000 requests\n",
    "Refs:\n",
    "\n",
    "https://medium.com/future-vision/google-maps-in-python-part-2-393f96196eaf\n",
    "https://developers.google.com/maps/documentation/geocoding/get-api-key\n",
    "https://github.com/pbugnion/gmaps/issues/79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GSV API key\n",
    "gsv_api_key_path = os.path.join(os.path.abspath(os.pardir), gsv_api_key_filename)\n",
    "\n",
    "print('Loading Google Street View API key from [{0:s}]'.format(gsv_api_key_path))\n",
    "\n",
    "with open(gsv_api_key_path) as f:\n",
    "    api_key = f.readline()\n",
    "    f.close\n",
    "\n",
    "# Configure a connection to the Google Maps API\n",
    "gmaps.configure(api_key=api_key)\n",
    "\n",
    "# Define a function to return the middle of a bounding box defined by two coordinates\n",
    "def mid_coords(lat1, lon1, lat2, lon2):\n",
    "    return ((lat1 + lat2)/2, (lon1 + lon2)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96e499b",
   "metadata": {},
   "source": [
    "Display a map of the above area.  Hard-coded coordinates are from the find_intersections example, above\n",
    "\n",
    "If the map does not display, install with Anaconda 3:\n",
    "\n",
    "`$ conda install -c conda-forge gmaps`\n",
    "\n",
    "Or with pip:\n",
    "\n",
    "`$ jupyter nbextension enable --py --sys-prefix widgetsnbextension`\n",
    "\n",
    "`$ pip install gmaps`\n",
    "\n",
    "`$ jupyter nbextension enable --py --sys-prefix gmaps`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmaps.figure(center=mid_coords(-37.8388277, 145.2113893, -37.8423446, 145.2132833), zoom_level=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-completion",
   "metadata": {},
   "source": [
    "## Find distinct [local_street] x [town] combinations in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-protest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include 'Existing' routes\n",
    "pbn_likely1 = pbn_exploded[pbn_exploded['status']=='Existing']\n",
    "\n",
    "# Filter to only include 'On Road' routes\n",
    "pbn_likely2 = pbn_likely1[pbn_likely1['type']=='On Road']\n",
    "\n",
    "# Filter to exclude 'n/a' streets\n",
    "pbn_likely = pbn_likely2[pbn_likely2['local_street'] != 'n/a']\n",
    "\n",
    "# Get distinct combinations\n",
    "pbn_distinct1 = pbn_likely.groupby(['objectid', 'local_street', 'town', 'suburb', 'city']).size().reset_index().rename(columns={0:'count'})\n",
    "\n",
    "# Get first row per objectid\n",
    "pbn_distinct = pbn_distinct1.groupby('objectid').first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-toner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a sample\n",
    "pbn_distinct.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-sapphire",
   "metadata": {},
   "source": [
    "Find all intersections for each of the roads.\n",
    "\n",
    "This is sometimes SLOW for a street.  E.g. there are 400x \"ALBERT STREET\" in Victoria,\n",
    "therefore we have to check each occurrence of \"ALBERT STREET\" in the dataset to EVERY\n",
    "street that intersects ANY \"ALBERT STREET\" in Victoria.  And we need to call the Nominatim\n",
    "web service to get the bounding box for each street involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-transformation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test run for just the first 6 entries, with debug messages\n",
    "log_starting('Find all intersections')\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "pbn_sample = pbn_distinct[:6].copy()\n",
    "pbn_sample.loc[:, 'intersections'] = pbn_sample.progress_apply(lambda x: find_intersections(x['local_street'], x['town'], x['suburb'], x['city'], objectid=x['objectid'], debug=1), axis=1)\n",
    "\n",
    "\n",
    "log_finished('Find all intersections')\n",
    "\n",
    "pbn_sample.head()\n",
    "print(pbn_sample['intersections'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-ceiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbn_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-crawford",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full run\n",
    "log_starting('Find all intersections')\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "pbn_full = pbn_distinct.copy()\n",
    "pbn_full['intersections'] = pbn_full.progress_apply(lambda x: find_intersections(x['local_street'], x['town'], x['suburb'], x['city'], objectid=x['objectid']), axis=1)\n",
    "\n",
    "log_finished('Find all intersections')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbn_full.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39105a28",
   "metadata": {},
   "source": [
    "We now have intersection data, but we don't have a heading to use at each intersection.  This means that when we ask Google Street View for images we can't control which way the camera is pointing.  We want it to be pointing forward in the first frame, then left, right, and to the rear.\n",
    "\n",
    "Calling the Google Street View API without a heading will give us the front view by default, but there is no way to tell it to give us e.g. the rear view relative to the car.  We must give headings relative to points on the compass.\n",
    "\n",
    "Therefore, before we save the output CSV, we want to work out a heading at each intersection.\n",
    "\n",
    "Define a function to work out the heading at each intersection.  We can use a Geodesic function to calculate the heading from one point to the next.  We therefore assume that the heading at an intersection is the average of:\n",
    "\n",
    "* The heading from the previous node to the intersection, and\n",
    "* The heading from the intersection to the next node\n",
    "\n",
    "If there is no previous node, or there is no next node, we just take the heading from what we do have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-shirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bearing_and_distance(objectid, intersection):\n",
    "    if type(intersection) != list:\n",
    "        return None\n",
    "    \n",
    "    lat = intersection[1]\n",
    "    lon = intersection[2]\n",
    "    \n",
    "    #print('int type: ' + str(type(intersection)) + ' value: ' + str(intersection))\n",
    "    #print('lat type: ' + str(type(lat)) + ' value: ' + str(lat))\n",
    "    #print('lon type: ' + str(type(lon)) + ' value: ' + str(lat))\n",
    "    \n",
    "    row = pbn[pbn['objectid']==objectid]\n",
    "    \n",
    "    gs = row['geometry']\n",
    "    \n",
    "    # Flatten into list of coordinates\n",
    "    coords_list = []\n",
    "    \n",
    "    for g in gs:\n",
    "        if type(g) is LineString:\n",
    "            for xy in g.coords:\n",
    "                coords_list.append((xy[1], xy[0]))\n",
    "        elif type(g) is MultiLineString:\n",
    "            for ls in g:\n",
    "                for xy in ls.coords:\n",
    "                    coords_list.append((xy[1], xy[0]))\n",
    "    \n",
    "    # Find the index of the closest point, and the distance in metres\n",
    "    coords_this  = (lat, lon)\n",
    "    \n",
    "    min_distance = 20000000\n",
    "    min_i        = -1\n",
    "    \n",
    "    for i in range(len(coords_list)):\n",
    "        distance = geopy.distance.distance(coords_this, coords_list[i]).m\n",
    "        \n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            min_i        = i\n",
    "\n",
    "    # Get bearing to previous and next point (if applicable)\n",
    "    if i > 0:\n",
    "        coords_prev = coords_list[i-1]\n",
    "        bearing_prev = Geodesic.WGS84.Inverse(coords_prev[0], coords_prev[1], lat, lon)['azi1']\n",
    "        if bearing_prev < 0:\n",
    "            bearing_prev = bearing_prev + 360\n",
    "    else:\n",
    "        bearing_prev = None\n",
    "        \n",
    "    if i < len(coords_list)-1:\n",
    "        coords_next = coords_list[i+1]\n",
    "        bearing_next = Geodesic.WGS84.Inverse(lat, lon, coords_next[0], coords_next[1])['azi1']\n",
    "        if bearing_next < 0:\n",
    "            bearing_next = bearing_next + 360\n",
    "    else:\n",
    "        bearing_next = None\n",
    "        \n",
    "    if   bearing_prev is None and bearing_next is not None:\n",
    "        bearing = round(bearing_next)\n",
    "    elif bearing_next is None and bearing_prev is not None:\n",
    "        bearing = round(bearing_prev)\n",
    "    else:\n",
    "        bearing = round((bearing_prev + bearing_next) / 2)\n",
    "    \n",
    "    # Return a list:\n",
    "    # 0: Bearing\n",
    "    # 1: Distance to closest point\n",
    "    # 2: Coordinates (lat, lon) of closest point\n",
    "    \n",
    "    return [bearing, min_distance, coords_list[i][0], coords_list[i][1]]\n",
    "\n",
    "# Example usage\n",
    "find_bearing_and_distance(1, [0, -38.1990811, 145.1044225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12178314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a test run of attempting to get a heading/bearing for each coordinate, with the sample data from earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbn_sample2 = pbn_sample.explode('intersections')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-ridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbn_sample2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-vancouver",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log_starting('Find bearings')\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "pbn_sample3 = pbn_sample2.copy()\n",
    "pbn_sample3.loc[:, 'bearings'] = pbn_sample3.progress_apply(lambda x: \\\n",
    "    find_bearing_and_distance(x['objectid'], x['intersections']), axis=1)\n",
    "\n",
    "log_finished('Find bearings')\n",
    "\n",
    "pbn_sample3.head()\n",
    "#print(pbn_sample3['bearings'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-pleasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100)\n",
    "print(pbn_sample3['bearings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-array",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "find_intersections('HYDE STREET', 'Seddon', 'Footscray', 'Melbourne', 616, debug=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a6b061",
   "metadata": {},
   "source": [
    "Find bearings at each intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbn_full2 = pbn_full.explode('intersections')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-potter",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_starting('Find bearings')\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "pbn_full3 = pbn_full2.copy()\n",
    "pbn_full3.loc[:, 'bearings'] = pbn_full3.progress_apply(lambda x: \\\n",
    "    find_bearing_and_distance(x['objectid'], x['intersections']), axis=1)\n",
    "\n",
    "log_finished('Find bearings')\n",
    "\n",
    "pbn_full3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11c4a16",
   "metadata": {},
   "source": [
    "Show the results just for the town of 'Mount Eliza'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-armor",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbn_full3[pbn_full3['town'] == 'Mount Eliza']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06ff437",
   "metadata": {},
   "source": [
    "Extracts parts of the 'geocode_list' column to separate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-imagination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract or derive geo fields from geocode_list\n",
    "\n",
    "def get_list_field(intersection, index):\n",
    "    if not (type(intersection)==list):\n",
    "        return None\n",
    "    return intersection[index]\n",
    "            \n",
    "log_starting('Extract intersection and bearing fields')\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "pbn_full4 = pbn_full3.copy()\n",
    "pbn_full4.loc[:, 'intersection_street'] = pbn_full4.progress_apply(lambda x: get_list_field(x['intersections'], 0), axis=1)\n",
    "pbn_full4.loc[:, 'intersection_lat']    = pbn_full4.progress_apply(lambda x: get_list_field(x['intersections'], 1), axis=1)\n",
    "pbn_full4.loc[:, 'intersection_lon']    = pbn_full4.progress_apply(lambda x: get_list_field(x['intersections'], 2), axis=1)\n",
    "pbn_full4.loc[:, 'bearing']             = pbn_full4.progress_apply(lambda x: get_list_field(x['bearings'], 0), axis=1)\n",
    "pbn_full4.loc[:, 'bearing_lat']         = pbn_full4.progress_apply(lambda x: get_list_field(x['bearings'], 1), axis=1)\n",
    "pbn_full4.loc[:, 'bearing_lon']         = pbn_full4.progress_apply(lambda x: get_list_field(x['bearings'], 2), axis=1)\n",
    "pbn_full4.drop(labels=['intersections', 'bearings'], axis=1, inplace=True)\n",
    "\n",
    "log_finished('Extract intersection and bearing fields')\n",
    "pbn_full4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fa2bca",
   "metadata": {},
   "source": [
    "Save the final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-particle",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_starting('Save intersections from PBN routes')\n",
    "\n",
    "output_intersections_path = os.path.join(os.path.abspath(os.pardir), 'data_sources', output_intersections_file)\n",
    "\n",
    "pbn_full4.to_csv(output_intersections_path)\n",
    "\n",
    "log_finished('Save intersections from PBN routes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
