{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d64d1c3",
   "metadata": {},
   "source": [
    "# 15. Apply Model to Train and Test Dashcam\n",
    "\n",
    "For every image in the \"train\" and \"test\" directories, process them through the model in such a way that we divide them into \"hits\" and \"misses\" and draw overlays.\n",
    "\n",
    "The purpose of this notebook is to allow us to inspect the results we get with the latest model on the \"train\" and especially the \"test\" dataset, to get an understanding of how it is performing beyond just the mAP and total loss stats.\n",
    "\n",
    "This is equivalent to notebook 08, but for dashcam footage instead of GSV footage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24497380",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Any configuration that is required to run this notebook can be customized in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ee8c400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trained detection model name\n",
    "trained_model_name   = 'centernet_V2_4000'\n",
    "\n",
    "# Prefix that will be included as a suffix in the label map file and tfrecord train and test files\n",
    "dataset_version = 'V2'\n",
    "\n",
    "# Confidence threshold to apply with the model.  The model must be at least\n",
    "# this confident of a detection for it to count\n",
    "confidence_threshold = 0.60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c357d8",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce231461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Make sure local modules can be imported\n",
    "module_path_root = os.path.abspath(os.pardir)\n",
    "if module_path_root not in sys.path:\n",
    "    sys.path.append(module_path_root)\n",
    "\n",
    "# Get root install path, a level above the minor_thesis folder from GitHub\n",
    "install_path_root = Path(module_path_root).parent.absolute()\n",
    "\n",
    "# Import local modules\n",
    "import osm_gsv_utils.osm_walker as osm_walker\n",
    "import osm_gsv_utils.gsv_loader as gsv_loader\n",
    "import tf2_utils.tf2_model_wrapper as tf2_model_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7ec609e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Release\n"
     ]
    }
   ],
   "source": [
    "# Derive paths\n",
    "\n",
    "# Derived path for main dataset images directory, train images directory, and test images directory\n",
    "image_train_dir   = os.path.join(install_path_root, 'TensorFlow', 'workspace', 'images', 'train_{0:s}'.format(dataset_version))\n",
    "image_test_dir    = os.path.join(install_path_root, 'TensorFlow', 'workspace', 'images', 'test_{0:s}'.format(dataset_version))\n",
    "\n",
    "# Output directory where the detection log and any images with detection overlays will be written\n",
    "output_directory_train = os.path.join(module_path_root, 'detections', 'train' + '_' + dataset_version)\n",
    "output_directory_test  = os.path.join(module_path_root, 'detections', 'test'  + '_' + dataset_version)\n",
    "\n",
    "# Output batch files for each directory\n",
    "output_batch_train = os.path.join(output_directory_train, 'batch.csv')\n",
    "output_batch_test  = os.path.join(output_directory_test,  'batch.csv')\n",
    "\n",
    "# Output CSV file with a log of all detections\n",
    "detection_log_train_path = os.path.join(output_directory_train, 'detection_log.csv')\n",
    "detection_log_test_path  = os.path.join(output_directory_train, 'detection_log.csv')\n",
    "\n",
    "# Create directories if they do not already exist\n",
    "Path(output_directory_train).mkdir(parents=True, exist_ok=True)\n",
    "Path(output_directory_test).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Change directory to make sure the detection model dependencies are found\n",
    "os.chdir(Path(module_path_root).parent.absolute())\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae4670c",
   "metadata": {},
   "source": [
    "## Create Batch Files\n",
    "\n",
    "Create batch files for the \"train\" and \"test\" directories that look like the one we will use when processing sample points from a survey area.  These batch files will drive the model to process those directories and output images with overlays, partitioned into \"hits\" and \"misses\" directories, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c234468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_directory_batch_file(input_directory, output_batch_file):\n",
    "    # List files in the directory\n",
    "    image_list = [f for f in os.listdir(input_directory) if not f.endswith('.xml')]\n",
    "    \n",
    "    file = open(output_batch_file, 'w')\n",
    "    file.write('lat,lon,bearing,image_path,way_start_id,way_id,node_id,offset_id\\n')\n",
    "    \n",
    "    for image in image_list:\n",
    "        file.write('0,0,0,{0:s},0,0,0,0\\n'.format(os.path.join(input_directory, image)))\n",
    "\n",
    "    file.close()\n",
    "    \n",
    "write_directory_batch_file(image_train_dir, output_batch_train)\n",
    "write_directory_batch_file(image_test_dir,  output_batch_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532295eb",
   "metadata": {},
   "source": [
    "## Apply Model to Batch Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92e37588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Output directory for detections: E:\\Release\\minor_thesis\\detections\\train_V2\n",
      "Label Map Path: [TensorFlow\\workspace\\annotations\\label_map_V2.pbtxt]\n",
      "Latest Checkpoint: ckpt-0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "894fd23837bf4c0191b1ab96b0a7d71d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\TensorFlow\\models\\research\\object_detection\\meta_architectures\\center_net_meta_arch.py:3769: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'E:\\\\Release\\\\minor_thesis\\\\detections\\\\train_V2\\\\detection_log.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise model\n",
    "model_wrapper = tf2_model_wrapper(\n",
    "    'train', \n",
    "    0, \n",
    "    image_train_dir, \n",
    "    output_directory_train, \n",
    "    trained_model_name, \n",
    "    version_suffix = dataset_version\n",
    ")\n",
    "\n",
    "# Run detections for entire batch\n",
    "model_wrapper.process_batch_file(\n",
    "    output_batch_train,\n",
    "    min_score      = confidence_threshold,\n",
    "    explicit_files = True,\n",
    "    progress       = True,\n",
    "    verbose        = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7651afa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Output directory for detections: E:\\Release\\minor_thesis\\detections\\test_V2\n",
      "Label Map Path: [TensorFlow\\workspace\\annotations\\label_map_V2.pbtxt]\n",
      "Latest Checkpoint: ckpt-0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f7c7fdc72fd45c18a52b4264aeda321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'E:\\\\Release\\\\minor_thesis\\\\detections\\\\test_V2\\\\detection_log.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise model\n",
    "model_wrapper = tf2_model_wrapper(\n",
    "    'test', \n",
    "    0, \n",
    "    image_test_dir, \n",
    "    output_directory_test, \n",
    "    trained_model_name, \n",
    "    version_suffix = dataset_version\n",
    ")\n",
    "\n",
    "# Run detections for entire batch\n",
    "model_wrapper.process_batch_file(\n",
    "    output_batch_test,\n",
    "    min_score      = confidence_threshold,\n",
    "    explicit_files = True,\n",
    "    progress       = True,\n",
    "    verbose        = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3a8282",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
