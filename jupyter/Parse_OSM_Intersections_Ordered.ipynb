{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d64d1c3",
   "metadata": {},
   "source": [
    "# Identify Sample Locations near Intersections and Download GSV images\n",
    "\n",
    "Find all intersections in an OSM extract, then create a CSV file with all the points near the intersections that we want to sample.\n",
    "\n",
    "We walk down each \"way\" in the OSM data and work out a heading  at each point, based on the average of the bearing from the previous point, and the bearing to the next point, in order to have some idea which heading to use in a Google Street View request to sample images (roughly) forward/backward/left/right.\n",
    "\n",
    "The items we are looking for might not be most visible from right in the middle of an intersection, therefore there is an option to specify a range around each intersection that we want to sample, along the heading.  E.g. if we specify 20m, then we will sample the point in the middle of the intersection, +/- 10m, and +/- 20m.  We use 10m intervals within this range because Google Street View typically gives a different image roughly every 10m.\n",
    "\n",
    "This \"ordered\" version supercedes an earlier version:  In OSM, a long street may be divided up into multiple connecting \"ways\", each with the same name.  Rather than walking down ways in random order, we attempt process ways in order of their name, and then within the name we attempt to identify a logical order:  Start with a way whose first node is NOT an intersection, then find the next way with the same name that intersects with the end of the first, and so on.  This isn't really necessary to generate a map of all the detections, but it is useful when visually inspecting the results to assess or measure the quality of the results:  It is less disorientating for a human to see the images in a logical \"walking\" order.\n",
    "\n",
    "Once we have a list of points to sample, we output a batch \"csv\" containing the way id, the node id of the sample point, the offset in metres (e.g. \"-20\"), the latitude, longitude, and bearing.  This can then be used to download and cache Google Street View images, and process them with our detection model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24497380",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Which \"locality\" do we wish to process?\n",
    "\n",
    "Assumes that we can find a pair of OSM files with corresponding names, extracted with the \"osmium\" tool.  One file follows the official shape of the locality, while a second file follows a bounding box around the locality with a 200m margin, so that when we are looking for intersections, we don't miss any due to the intersecting road being just outside the boundary of the locality (apart from the intersection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ee8c400",
   "metadata": {},
   "outputs": [],
   "source": [
    "locality = 'Mount Eliza Sample'\n",
    "margin   = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c357d8",
   "metadata": {},
   "source": [
    "## Import required code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce231461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Make sure local modules can be imported\n",
    "module_path_root = os.path.abspath(os.pardir)\n",
    "if module_path_root not in sys.path:\n",
    "    sys.path.append(module_path_root)\n",
    "    \n",
    "# Import local modules\n",
    "import osm_gsv_utils.osm_walker as osm_walker\n",
    "import osm_gsv_utils.gsv_loader as gsv_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fa9e44",
   "metadata": {},
   "source": [
    "## Identify sample points\n",
    "\n",
    "Load the OSM data, and then generate lists of sample points at margins of 0, +/- 10m, and +/- 20m from each intersection,\n",
    "and report on how many samples are found for each sample setting, to get an idea of the impact of increasing/decreasing\n",
    "the margin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7ec609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive paths for configuration\n",
    "\n",
    "locality_clean = locality.replace(' ', '_')\n",
    "\n",
    "filename_main       = os.path.join(os.pardir, 'data_sources', 'Locality_' + locality_clean + '.osm')\n",
    "filename_margin     = os.path.join(os.pardir, 'data_sources', 'Locality_' + locality_clean + '_margin.osm')\n",
    "locality_margin     = '{0:s}_{1:d}m'.format(locality_clean, margin)\n",
    "\n",
    "detection_filename  = os.path.join(\n",
    "    module_path_root,\n",
    "    'detections',\n",
    "    locality_margin,\n",
    "    'detection_log.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab209061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+/- 20m: 1851\n",
      "+/- 10m: 1181\n",
      "+/- 00m: 511\n"
     ]
    }
   ],
   "source": [
    "# Load OSM data\n",
    "walker = osm_walker(filename_main, filename_margin, verbose=False)\n",
    "\n",
    "# Generate sample lists with different margin settings, and report sample point count for each\n",
    "sample_points_20 = walker.sample_all_way_intersections(-20, +20, 10, ordered=True, verbose=False)\n",
    "sample_points_10 = walker.sample_all_way_intersections(-10, +10, 10, ordered=True, verbose=False)\n",
    "sample_points_00 = walker.sample_all_way_intersections(  0,   0, 10, ordered=True, verbose=False)\n",
    "\n",
    "print('+/- 20m: ' + str(len(sample_points_20)))\n",
    "print('+/- 10m: ' + str(len(sample_points_10)))\n",
    "print('+/- 00m: ' + str(len(sample_points_00)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59885f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-38.1611285, 145.1035642, 202, 0, '809849739', '770308568', '7190614708']\n"
     ]
    }
   ],
   "source": [
    "# Show sample structure of each point\n",
    "# [lat, lon, bearing, offset, way_start_id, way_id, node_id]\n",
    "\n",
    "print(sample_points_20[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae4670c",
   "metadata": {},
   "source": [
    "## Download/Cache GSV images\n",
    "\n",
    "Download GSV images (if not already cached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c234468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup D:\\TensorFlow2\\TFODCourse\\minor_thesis\\batches\\Mount_Eliza_Sample_20m.csv to D:\\TensorFlow2\\TFODCourse\\minor_thesis\\batches\\Mount_Eliza_Sample_20m20210920_142048.csv\n",
      "Write D:\\TensorFlow2\\TFODCourse\\minor_thesis\\batches\\Mount_Eliza_Sample_20m.csv\n"
     ]
    }
   ],
   "source": [
    "download_directory = os.path.join(module_path_root, 'data_sources', 'gsv')\n",
    "apikey_filename    = os.path.join(module_path_root, 'apikey.txt')\n",
    "batch_filename     = os.path.join(module_path_root, 'batches', locality_clean + '_20m.csv')\n",
    "output_geojson     = os.path.join(module_path_root, 'detections', locality_margin, 'detected_points.geojson')\n",
    "\n",
    "# Initialise interface to Google Street View\n",
    "gsv = gsv_loader(apikey_filename, download_directory)\n",
    "\n",
    "# Create a batch file (CSV) with the list of locations to download from Google\n",
    "# limit=0 means unlimited, set to a small integer to test a few downloads\n",
    "gsv.write_batch_file(batch_filename, sample_points_20, limit=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a8bbd42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7cb2794f94e426cbc5fe4bd63a1765c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1851 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSV Cache Hits:       7404 Misses:          0\n"
     ]
    }
   ],
   "source": [
    "# Process the batch file (with progress bar) and report how many images were fetched vs. skipped\n",
    "# Working from a batch file means we have a permanent record of what was loaded (in case we need to resume later)\n",
    "# and helps us implement a progress bar via tdqm\n",
    "gsv.process_batch_file(batch_filename, progress=True, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b9cf99",
   "metadata": {},
   "source": [
    "## Load Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0b7f4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load detections from Apply_Model.ipynb\n",
    "\n",
    "walker.load_detection_log(detection_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beeb1933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7190614708     0 => 0 1 0 -38.161128, 145.103564\n",
      "638345374      1 => 1 0 2 -38.161668, 145.103287\n",
      "113302198      2 => 0 0 2 -38.162533, 145.102853\n",
      "367133525      3 => 1 1 0 -38.163992, 145.102131\n",
      "30204320       4 => 0 0 1 -38.164266, 145.102000\n",
      "638345569      5 => 0 0 1 -38.164538, 145.101855\n",
      "30204321       6 => 0 0 1 -38.164804, 145.101766\n",
      "638345571      7 => 0 0 1 -38.165148, 145.101686\n",
      "768939206      8 => 1 1 0 -38.165326, 145.101653\n",
      "30204322       9 => 0 0 1 -38.165519, 145.101643\n",
      "638345574     10 => 0 0 1 -38.165842, 145.101664\n",
      "638345577     11 => 0 0 1 -38.166244, 145.101691\n",
      "30204323      12 => 1 1 0 -38.166706, 145.101747\n",
      "607647718     13 => 1 1 0 -38.166812, 145.101755\n",
      "30204324      14 => 0 0 1 -38.167470, 145.101785\n",
      "638345589     15 => 0 0 1 -38.167824, 145.101774\n",
      "638345592     16 => 0 0 1 -38.168130, 145.101712\n",
      "30204325      17 => 0 0 1 -38.168518, 145.101619\n",
      "638345603     18 => 0 0 1 -38.168994, 145.101463\n",
      "30204326      19 => 0 0 1 -38.169395, 145.101265\n",
      "638345610     20 => 0 0 1 -38.169808, 145.101010\n",
      "607646869     21 => 1 1 0 -38.170287, 145.100666\n",
      "30204327      22 => 0 0 1 -38.170698, 145.100353\n",
      "638345796     23 => 0 0 1 -38.170980, 145.100174\n",
      "30204328      24 => 0 0 1 -38.171329, 145.099972\n",
      "314772691     25 => 0 0 1 -38.171833, 145.099714\n",
      "638345797     26 => 0 0 1 -38.172149, 145.099524\n",
      "30204329      27 => 0 0 1 -38.172457, 145.099288\n",
      "314770787     28 => 0 0 1 -38.172820, 145.098950\n",
      "638345798     29 => 0 0 1 -38.173045, 145.098674\n",
      "30204330      30 => 0 0 1 -38.173231, 145.098416\n",
      "638345799     31 => 0 0 1 -38.173526, 145.097976\n",
      "30204331      32 => 0 0 1 -38.173829, 145.097587\n",
      "638345800     33 => 0 0 1 -38.174106, 145.097343\n",
      "638345801     34 => 0 0 1 -38.174376, 145.097158\n",
      "30204332      35 => 0 0 1 -38.174671, 145.097024\n",
      "638345802     36 => 0 0 1 -38.174981, 145.096919\n",
      "30204333      37 => 0 0 1 -38.175312, 145.096874\n",
      "638345803     38 => 0 0 1 -38.175677, 145.096866\n",
      "314772434     39 => 0 0 1 -38.176318, 145.096901\n",
      "638345804     40 => 0 0 1 -38.176665, 145.096877\n",
      "638345805     41 => 0 0 1 -38.177066, 145.096825\n",
      "30204334      42 => 0 0 1 -38.177492, 145.096740\n",
      "638345806     43 => 0 0 1 -38.177941, 145.096632\n",
      "638345807     44 => 0 0 1 -38.178312, 145.096525\n",
      "638345808     45 => 0 0 1 -38.179157, 145.096229\n"
     ]
    }
   ],
   "source": [
    "walker.draw_way_segment('809849739', intersection_skip_limit=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f977d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to: D:\\TensorFlow2\\TFODCourse\\minor_thesis\\detections\\Mount_Eliza_Sample_20m\\detected_points.geojson\n"
     ]
    }
   ],
   "source": [
    "walker.write_detected_geojson(locality_margin, output_geojson, intersection_skip_limit=1, verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
