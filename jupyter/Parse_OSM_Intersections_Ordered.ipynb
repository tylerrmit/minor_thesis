{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d64d1c3",
   "metadata": {},
   "source": [
    "# Identify Sample Locations near Intersections and Download GSV images\n",
    "\n",
    "Find all intersections in an OSM extract, then create a CSV file with all the points near the intersections that we want to sample.\n",
    "\n",
    "We walk down each \"way\" in the OSM data and work out a heading  at each point, based on the average of the bearing from the previous point, and the bearing to the next point, in order to have some idea which heading to use in a Google Street View request to sample images (roughly) forward/backward/left/right.\n",
    "\n",
    "The items we are looking for might not be most visible from right in the middle of an intersection, therefore there is an option to specify a range around each intersection that we want to sample, along the heading.  E.g. if we specify 20m, then we will sample the point in the middle of the intersection, +/- 10m, and +/- 20m.  We use 10m intervals within this range because Google Street View typically gives a different image roughly every 10m.\n",
    "\n",
    "This \"ordered\" version supercedes an earlier version:  In OSM, a long street may be divided up into multiple connecting \"ways\", each with the same name.  Rather than walking down ways in random order, we attempt process ways in order of their name, and then within the name we attempt to identify a logical order:  Start with a way whose first node is NOT an intersection, then find the next way with the same name that intersects with the end of the first, and so on.  This isn't really necessary to generate a map of all the detections, but it is useful when visually inspecting the results to assess or measure the quality of the results:  It is less disorientating for a human to see the images in a logical \"walking\" order.\n",
    "\n",
    "Once we have a list of points to sample, we output a batch \"csv\" containing the way id, the node id of the sample point, the offset in metres (e.g. \"-20\"), the latitude, longitude, and bearing.  This can then be used to download and cache Google Street View images, and process them with our detection model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24497380",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Which \"locality\" do we wish to process?\n",
    "\n",
    "Assumes that we can find a pair of OSM files with corresponding names, extracted with the \"osmium\" tool.  One file follows the official shape of the locality, while a second file follows a bounding box around the locality with a 200m margin, so that when we are looking for intersections, we don't miss any due to the intersecting road being just outside the boundary of the locality (apart from the intersection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ee8c400",
   "metadata": {},
   "outputs": [],
   "source": [
    "locality = 'Mount Eliza Sample'\n",
    "margin   = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c357d8",
   "metadata": {},
   "source": [
    "## Import required code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce231461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Make sure local modules can be imported\n",
    "module_path_root = os.path.abspath(os.pardir)\n",
    "if module_path_root not in sys.path:\n",
    "    sys.path.append(module_path_root)\n",
    "    \n",
    "# Import local modules\n",
    "import osm_gsv_utils.osm_walker as osm_walker\n",
    "import osm_gsv_utils.gsv_loader as gsv_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fa9e44",
   "metadata": {},
   "source": [
    "## Identify sample points\n",
    "\n",
    "Load the OSM data, and then generate lists of sample points at margins of 0, +/- 10m, and +/- 20m from each intersection,\n",
    "and report on how many samples are found for each sample setting, to get an idea of the impact of increasing/decreasing\n",
    "the margin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7ec609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive paths for configuration\n",
    "\n",
    "locality_clean = locality.replace(' ', '_')\n",
    "\n",
    "filename_main       = os.path.join(os.pardir, 'data_sources', 'Locality_' + locality_clean + '.osm')\n",
    "filename_margin     = os.path.join(os.pardir, 'data_sources', 'Locality_' + locality_clean + '_margin.osm')\n",
    "locality_margin     = '{0:s}_{1:d}m'.format(locality_clean, margin)\n",
    "\n",
    "detection_filename  = os.path.join(\n",
    "    module_path_root,\n",
    "    'detections',\n",
    "    locality_margin,\n",
    "    'detection_log.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab209061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+/- 20m: 1851\n",
      "+/- 10m: 1181\n",
      "+/- 00m: 511\n"
     ]
    }
   ],
   "source": [
    "# Load OSM data\n",
    "walker = osm_walker(filename_main, filename_margin, verbose=False)\n",
    "\n",
    "# Generate sample lists with different margin settings, and report sample point count for each\n",
    "sample_points_20 = walker.sample_all_way_intersections(-20, +20, 10, ordered=True, verbose=False)\n",
    "sample_points_10 = walker.sample_all_way_intersections(-10, +10, 10, ordered=True, verbose=False)\n",
    "sample_points_00 = walker.sample_all_way_intersections(  0,   0, 10, ordered=True, verbose=False)\n",
    "\n",
    "print('+/- 20m: ' + str(len(sample_points_20)))\n",
    "print('+/- 10m: ' + str(len(sample_points_10)))\n",
    "print('+/- 00m: ' + str(len(sample_points_00)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59885f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-38.1611285, 145.1035642, 202, 0, '809849739', '770308568', '7190614708']\n"
     ]
    }
   ],
   "source": [
    "# Show sample structure of each point\n",
    "# [lat, lon, bearing, offset, way_start_id, way_id, node_id]\n",
    "\n",
    "print(sample_points_20[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae4670c",
   "metadata": {},
   "source": [
    "## Download/Cache GSV images\n",
    "\n",
    "Download GSV images (if not already cached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c234468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup D:\\TensorFlow2\\TFODCourse\\minor_thesis\\batches\\Mount_Eliza_Sample_20m.csv to D:\\TensorFlow2\\TFODCourse\\minor_thesis\\batches\\Mount_Eliza_Sample_20m20210922_184251.csv\n",
      "Write D:\\TensorFlow2\\TFODCourse\\minor_thesis\\batches\\Mount_Eliza_Sample_20m.csv\n"
     ]
    }
   ],
   "source": [
    "download_directory = os.path.join(module_path_root, 'data_sources', 'gsv')\n",
    "apikey_filename    = os.path.join(module_path_root, 'apikey.txt')\n",
    "batch_filename     = os.path.join(module_path_root, 'batches', locality_clean + '_20m.csv')\n",
    "geojson_directory  = os.path.join(module_path_root, 'detections', locality_margin)\n",
    "\n",
    "# Initialise interface to Google Street View\n",
    "gsv = gsv_loader(apikey_filename, download_directory)\n",
    "\n",
    "# Create a batch file (CSV) with the list of locations to download from Google\n",
    "# limit=0 means unlimited, set to a small integer to test a few downloads\n",
    "gsv.write_batch_file(batch_filename, sample_points_20, limit=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a8bbd42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5572d3c4d4749928f0fc1d5f719c94c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1851 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSV Cache Hits:       7404 Misses:          0\n"
     ]
    }
   ],
   "source": [
    "# Process the batch file (with progress bar) and report how many images were fetched vs. skipped\n",
    "# Working from a batch file means we have a permanent record of what was loaded (in case we need to resume later)\n",
    "# and helps us implement a progress bar via tdqm\n",
    "gsv.process_batch_file(batch_filename, progress=True, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b9cf99",
   "metadata": {},
   "source": [
    "## Load Detections\n",
    "\n",
    "Stop and run \"Apply Model\", then come back to this to load the results and correlate them against OSM tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0b7f4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load detections from Apply_Model.ipynb\n",
    "\n",
    "walker.load_detection_log(detection_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f977d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hit, feature count: 10\n",
      "Writing to: D:\\TensorFlow2\\TFODCourse\\minor_thesis\\detections\\Mount_Eliza_Sample_20m\\hit.geojson\n",
      "Writing tag, feature count: 2\n",
      "Writing to: D:\\TensorFlow2\\TFODCourse\\minor_thesis\\detections\\Mount_Eliza_Sample_20m\\tag.geojson\n",
      "Writing both, feature count: 2\n",
      "Writing to: D:\\TensorFlow2\\TFODCourse\\minor_thesis\\detections\\Mount_Eliza_Sample_20m\\both.geojson\n",
      "Writing hit_only, feature count: 9\n",
      "Writing to: D:\\TensorFlow2\\TFODCourse\\minor_thesis\\detections\\Mount_Eliza_Sample_20m\\hit_only.geojson\n",
      "Writing tag_only, feature count: 0\n",
      "Writing to: D:\\TensorFlow2\\TFODCourse\\minor_thesis\\detections\\Mount_Eliza_Sample_20m\\tag_only.geojson\n"
     ]
    }
   ],
   "source": [
    "walker.write_geojsons(locality_margin, geojson_directory, intersection_skip_limit=1, verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
