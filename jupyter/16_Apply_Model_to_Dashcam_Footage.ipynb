{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c59ab8a6",
   "metadata": {},
   "source": [
    "# 16. Apply Model to Dashcam Footage\n",
    "\n",
    "Given a folder of dashcam footage that has been \"split\" into images and \"metadata.csv\" in the previous notebook, process all the images with a detection model.\n",
    "\n",
    "Outputs:\n",
    "* A \"detections\" subdirectory next to the \"split\" directory of images, containing:\n",
    "    * \"hits\" - a directory of images where a bicycle lane marking was found, with an overlay displaying where in the frame and the confidence level\n",
    "    * \"miss\" - a directory of images where a bicycle lane marking was NOT found, with overlays for any other object types that were detected\n",
    "    * \"detection_log.csv\" - a CSV with details of the frames where a bicycle lane marking was found, including location information\n",
    "\n",
    "NOTE: During the experiment, this notebook was used several times:\n",
    "\n",
    "* The first time, we used the model that had been trained on GSV images as-is, without re-training with any dashcam images\n",
    "\n",
    "The resulting \"hits\" images -- including false positives -- were labelled and added to the training dataset, and the model was re-trained with a mix of GSV and dashcam images.\n",
    "\n",
    "* The second time, we used the model that had been trained on a mix of GSV images and dashcam images\n",
    "\n",
    "Inspection of the resulting \"hits\" images showed that we were getting false postives due to things such as white markings on the road to \"give way\" or indicate a traffic island, or a turning lane.  The images were therefore re-labelled to include additional classes to be ignored.  These deterred the model from e.g. assuming a white turning lane might be most similar to a white bicycle lane marking.\n",
    "\n",
    "* The third time, we used the model that had been trained on a mix of GSV images and dashcam images with multiple decoy classes, and we applied a mask to ignore parts of the frame other than the left hand side of the road.\n",
    "\n",
    "Using the dash camera footage, we have potentialy many more images to go on than just Google Street View, and we should usually expect an actual bicycle lane marker to be detected in a sequence of frames that are close to each other in time and space.\n",
    "\n",
    "Therefore, once we have the usual \"detection_log.csv\" containing a list of ALL frames where we detected bicycle lane markings, we apply a \"filtering\" process to filter that list down to ONLY detections where there were a minimum number of \"hits\" within a distance range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b1d932",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Any configuration that is required to run this notebook can be customized in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66afdcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the subdirectory containing dashcam footage for an area, split into frame images in a\n",
    "# \"split\" subdirectory, with an associated \"metadata.csv\"\n",
    "# This subdirectory is assumed to be in the 'data_sources' directory\n",
    "import_directory = 'dashcam_tour_mount_eliza'\n",
    "#import_directory = 'dashcam_tour_frankston'\n",
    "\n",
    "# Confidence threshold to apply with the model.  The model must be at least\n",
    "# this confident of a detection for it to count\n",
    "confidence_threshold = 0.60\n",
    "\n",
    "# Trained detection model name\n",
    "# You might wish to \"freeze\" a versioned copy of a model and give it a name\n",
    "trained_model_name   = 'centernet_hg104_512x512_coco17_tpu-8'\n",
    "#trained_model_name   = 'centernet_V1' # Trained on GSV only\n",
    "#trained_model_name   = 'centernet_V2' # Trained on GSV plus some dashcam footage\n",
    "#trained_model_name   = 'centernet_V3' # Trained on CSV plus dashcam with false positives (2000 steps)\n",
    "#trained_model_name   = 'centernet_V4' # Add RoadDefect and RoadWriting classes to model (2000 steps)\n",
    "#trained_model_name   = 'centernet_V5' # V4 but with 30,000 steps\n",
    "\n",
    "# Prefix that will be included as a suffix in the label map file and tfrecord train and test files\n",
    "dataset_version = 'V1'\n",
    "#dataset_version = 'V2'\n",
    "\n",
    "# Detection Mask.  An optional array of pixel coordinates within the frame to include.\n",
    "# Output images will show this outline as a blue overlay.\n",
    "# If this is set to None, there is no mask.\n",
    "# The example mask below excludes the bonnet of the car (which can sometimes cause false-positives\n",
    "# due to reflections) and the right-hand side of the road\n",
    "#mask = None\n",
    "mask = [[0, 0], [0, 720], [480, 650], [950, 650], [950, 0]]\n",
    "\n",
    "# When applying a filter to \"detection_log.csv\" to reduce it down to \"detection_log_filtered.csv\"\n",
    "# to eliminate \"lonely\" outlier detections that are not supported by adjacent detections:\n",
    "min_hits_in_range    = 2   # There must be a minimum of this many hits within a distance range\n",
    "min_range_from_hit   = 10  # Other hits must be at least this many metres away to count as support\n",
    "max_range_from_hit   = 50  # Other hits that are more than this many metres away do not count\n",
    "\n",
    "# E.g. to include the detection in the filtered list, there must be at least two other hits within\n",
    "# a range >= 10m and <=50m of the original hit for it to count.\n",
    "# If the vehicle is stationary, giving way to traffic, then the minimum 10m will ensure that these\n",
    "# effectively \"identical\" images do not artifically support each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3002fdfb",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a07f3b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from ipyleaflet import Map, GeoJSON\n",
    "\n",
    "# Make sure local modules can be imported\n",
    "module_path_root = os.path.abspath(os.pardir)\n",
    "if module_path_root not in sys.path:\n",
    "    sys.path.append(module_path_root)\n",
    "    \n",
    "# Import local modules\n",
    "import tf2_utils.tf2_model_wrapper as tf2_model_wrapper\n",
    "import osm_gsv_utils.detection_map as detection_map\n",
    "import osm_gsv_utils.detection_log_filter as detection_log_filter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d9a2087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch file: [E:\\Release\\minor_thesis\\data_sources\\dashcam_tour_mount_eliza\\split\\metadata.csv]\n"
     ]
    }
   ],
   "source": [
    "# Derive paths\n",
    "\n",
    "download_directory = os.path.join(module_path_root, 'data_sources', import_directory, 'split')\n",
    "batch_filename     = os.path.join(module_path_root, 'data_sources', import_directory, 'split', 'metadata.csv')\n",
    "output_directory   = os.path.join(module_path_root, 'data_sources', import_directory, 'detections')\n",
    "\n",
    "print('Processing batch file: [{0:s}]'.format(batch_filename))\n",
    "\n",
    "# Change directory to make sure the detection model dependencies are found\n",
    "os.chdir(Path(module_path_root).parent.absolute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "462d9d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a mask was specified, initliase a numpy version of it\n",
    "\n",
    "if mask is not None:\n",
    "    mask_np = np.array(mask)\n",
    "else:\n",
    "    mask_np = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9edad0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Output directory for detections: E:\\Release\\minor_thesis\\data_sources\\dashcam_tour_mount_eliza\\detections\n",
      "Label Map Path: [TensorFlow\\workspace\\annotations\\label_map_V1.pbtxt]\n",
      "Latest Checkpoint: ckpt-18\n"
     ]
    }
   ],
   "source": [
    "# Initialise model\n",
    "model_wrapper = tf2_model_wrapper(\n",
    "    import_directory, \n",
    "    0, \n",
    "    download_directory, \n",
    "    output_directory, \n",
    "    trained_model_name,\n",
    "    version_suffix = dataset_version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bb31bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "466bde8c35dc40219236b1e6e3205118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13545 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\TensorFlow\\models\\research\\object_detection\\meta_architectures\\center_net_meta_arch.py:3769: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    }
   ],
   "source": [
    "# Run detection for entire batch\n",
    "detection_log = model_wrapper.process_split_dir(\n",
    "    batch_filename,\n",
    "    min_score = confidence_threshold,\n",
    "    mask      = mask_np,\n",
    "    progress  = True,\n",
    "    verbose   = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b1d11da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f005abc36032476a842afb5d171ac08b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a filtered version of \"detection_log.csv\" called \"detection_log_filtered.csv\"\n",
    "# according to the configured rules\n",
    "filter = detection_log_filter(os.path.join(output_directory, 'detection_log.csv'))\n",
    "\n",
    "filter.apply_filter(\n",
    "    os.path.join(output_directory, 'detection_log_filtered.csv'),\n",
    "    min_hits_in_range  = 2,\n",
    "    min_range_from_hit = 5,\n",
    "    max_range_from_hit = 200\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuEnv",
   "language": "python",
   "name": "gpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
